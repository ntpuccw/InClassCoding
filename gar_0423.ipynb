{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01119834",
   "metadata": {},
   "source": [
    "**<font color=skyblue>使用 LogisticRegression 與 LogisticRegressionCV 進行分類</font>**\n",
    "\n",
    "Data: Wine.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879a6cc",
   "metadata": {},
   "source": [
    "<font color=yellow>Prepare Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23450fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 124\n",
      "Testing samples: 54\n",
      "Training data shape: (124, 13)\n",
      "Testing data shape: (54, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data\n",
    "df = pd.read_excel('data/Wine.xlsx')\n",
    "X = np.array(df.iloc[:, :-1]) # 排除最後一欄標籤 N x p\n",
    "y = np.array(df.iloc[:, -1])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "# 70% training, 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X_train) # 標準化訓練資料\n",
    "X_test_ = scaler.fit_transform(X_test) # 標準化測試資料\n",
    "\n",
    "# print the numbers of training and testing samples\n",
    "print(f\"Training samples: {X_train_.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test_.shape[0]}\")\n",
    "# print the shape of the data\n",
    "print(f\"Training data shape: {X_train_.shape}\")\n",
    "print(f\"Testing data shape: {X_test_.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43efdf",
   "metadata": {},
   "source": [
    "<font color=yellow>Use original data to train the machine by</font>\n",
    "\n",
    "- LogisticRegression\n",
    "- LogisticRegressionCV: LogisticRegression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147a2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with solver = lbfgs\n",
      "Training score = 100.00%\n",
      "\n",
      "Testint score = 87.04%\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      1.00      0.76         8\n",
      "           2       1.00      0.73      0.84        26\n",
      "           3       0.91      1.00      0.95        20\n",
      "\n",
      "    accuracy                           0.87        54\n",
      "   macro avg       0.84      0.91      0.85        54\n",
      "weighted avg       0.91      0.87      0.87        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# clf_original = LogisticRegression(solver = 'lbfgs', tol = 1e-6, max_iter = int(1e6), verbose=True)\n",
    "# setup parameters for LogisticRegression\n",
    "opts = dict(tol = 1e-6, max_iter = int(1e6), verbose=0) # verbose=1 for more information\n",
    "# --- Logistic Regression ---\n",
    "solver = 'lbfgs'  # 'lbfgs' is the default\n",
    "# solver = 'liblinear'\n",
    "# solver = 'newton-cg'\n",
    "clf_LR_original = LogisticRegression(solver = solver, **opts)\n",
    "clf_LR_original.fit(X_train_, y_train) # input data must be (n_samples x n_features)\n",
    "# --- Results Report ---\n",
    "print(f\"Logistic Regression with solver = {solver}\")\n",
    "# print training score\n",
    "print(f\"Training score = {accuracy_score(y_train, clf_LR_original.predict(X_train_)):.2%}\\n\")\n",
    "# print testing score\n",
    "y_pred = clf_LR_original.predict(X_test_)\n",
    "# print(f\"Testing score = {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Testint score = {clf_LR_original.score(X_test_, y_test):.2%}\\n\")\n",
    "# print classification report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60738fe6",
   "metadata": {},
   "source": [
    "<font color=yellow>Use LogisticRegressionCV</font>\n",
    "\n",
    "Cross Validation with respect to Cs parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eafc017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Cross Validation and solver = lbfgs\n",
      "Best C = [0.16237767 0.16237767 0.16237767]\n",
      "Training score = 100.00%\n",
      "\n",
      "Testing score = 88.89%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      1.00      0.76         8\n",
      "           2       1.00      0.77      0.87        26\n",
      "           3       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.89        54\n",
      "   macro avg       0.86      0.92      0.87        54\n",
      "weighted avg       0.93      0.89      0.89        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "opts = dict(tol = 1e-6, max_iter = int(1e6), verbose=0)\n",
    "solver = 'lbfgs'  # 'lbfgs' is the default\n",
    "# solver = 'liblinear'\n",
    "# solver = 'newton-cg'\n",
    "Cs = np.logspace(-5, 5, 20) # 20 values of C from 1e-5 to 1e5\n",
    "cv = 5 # 5-fold cross-validation\n",
    "# --- Logistic Regression with Cross Validation ---\n",
    "clf_originalCV = LogisticRegressionCV(solver = solver, Cs = Cs, cv = cv, **opts) \n",
    "clf_originalCV.fit(X_train_, y_train) # input data must be (n_samples x n_features)\n",
    "y_pred = clf_originalCV.predict(X_test_)\n",
    "\n",
    "# --- Results Report ---\n",
    "print(f\"Logistic Regression with Cross Validation and solver = {solver}\")\n",
    "# print best C value\n",
    "print(f\"Best C = {clf_originalCV.C_}\")\n",
    "# print training score\n",
    "print(f\"Training score = {accuracy_score(y_train, clf_originalCV.predict(X_train_)):.2%}\\n\")\n",
    "# print testing score\n",
    "# print(f\"Testing score = {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Testing score = {clf_originalCV.score(X_test_, y_test):.2%}\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f7dc2",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font color=yellow>Use principal components to train the machine</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d621de32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b00a05d6",
   "metadata": {},
   "source": [
    "<font color=yellow>最佳組合選擇 by GridSearchCV</font>\n",
    "\n",
    "CV: Cross Validation 用在 hyperparameter tuning\n",
    "\n",
    "<font color=red>警告：資料量大時，很費時</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51bb9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'solver': 'liblinear'}\n",
      "1.0\n",
      "LogisticRegression(C=0.1, max_iter=1000000, solver='liblinear', tol=1e-06)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import  GridSearchCV, \\\n",
    "                        StratifiedShuffleSplit\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "# Format the date and time as a string\n",
    "now_str = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "results_file = 'data/results_' + now_str + '.csv'\n",
    "\n",
    "opts = dict(tol = 1e-6, max_iter = int(1e6)) # parameters for LogisticRegression\n",
    "parameters = {'solver':['lbfgs', 'liblinear', 'newton-cg', 'sag','saga'], \\\n",
    "              'C':[0.1, 1, 10]} # parameters for GridSearchCV\n",
    "# parameters = {'solver':['lbfgs', 'liblinear', 'newton-cg',\\\n",
    "#                         'sag','saga']}\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.3, \\\n",
    "                            random_state=0) # 5-fold CV\n",
    "grid = GridSearchCV(estimator=LogisticRegression(**opts), \\\n",
    "                param_grid=parameters, cv=cv, \n",
    "                scoring=['accuracy','f1_macro'], refit=\"accuracy\") \n",
    "grid.fit(X_train_, y_train)\n",
    "# grid.fit(X, y)\n",
    "cv_logistic = pd.DataFrame(data = grid.cv_results_)\n",
    "# print the results\n",
    "# print(cv_logistic.head())\n",
    "# cv_logistic.to_csv(results_file) # 打開來觀察結果\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
